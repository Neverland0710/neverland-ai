from datetime import datetime, date
from typing import List, Dict, Optional
import os
import logging
import asyncio
import threading

from langchain_openai import OpenAIEmbeddings
from langchain_qdrant import QdrantVectorStore 
from langchain.schema import Document
from qdrant_client import QdrantClient
from qdrant_client.models import Filter, FieldCondition, MatchValue

from app.config import settings
from app.utils.logger import logger

logger = logging.getLogger("memorial_chat")

# LangSmith ì¶”ì  ì—°ë™
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_API_KEY"] = settings.langsmith_api_key
os.environ["LANGCHAIN_PROJECT"] = settings.langsmith_project

def format_date_relative(memory_date: str) -> str:
    """ë‚ ì§œë¥¼ ìƒëŒ€ì  í‘œí˜„ìœ¼ë¡œ ë³€í™˜"""
    try:
        mem_date = datetime.strptime(memory_date, "%Y-%m-%d").date()
        today = date.today()
        delta = (today - mem_date).days

        if delta == 0:
            return "ì˜¤ëŠ˜ ìˆì—ˆë˜ ì¼"
        elif delta == 1:
            return "ì–´ì œ ìˆì—ˆë˜ ì¼"
        elif delta < 7:
            return f"{delta}ì¼ ì „ì— ìˆì—ˆë˜ ì¼"
        elif mem_date.year == today.year:
            return f"{mem_date.month}ì›” {mem_date.day}ì¼ì— ìˆì—ˆë˜ ì¼"
        else:
            return f"{mem_date.year}ë…„ {mem_date.month}ì›” {mem_date.day}ì¼ì— ìˆì—ˆë˜ ì¼"
    except:
        return "ë‚ ì§œ ë¯¸ìƒ"

class AdvancedRAGService:
    """ Singleton íŒ¨í„´ìœ¼ë¡œ ì¤‘ë³µ ì´ˆê¸°í™” ë°©ì§€"""
    _instance = None
    _lock = threading.Lock()
    _initialized = False

    def __new__(cls):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super(AdvancedRAGService, cls).__new__(cls)
        return cls._instance

    def __init__(self):
        #  ì¤‘ë³µ ì´ˆê¸°í™” ë°©ì§€
        if self._initialized:
            logger.debug(" AdvancedRAGService ì´ë¯¸ ì´ˆê¸°í™”ë¨ - ì¬ì‚¬ìš©")
            return
            
        with self._lock:
            if self._initialized:
                return
                
            logger.info(" AdvancedRAGService ì´ˆê¸°í™” ì‹œì‘...")
            
            try:
                self.embeddings = OpenAIEmbeddings(
                    model="text-embedding-3-small",
                    openai_api_key=settings.openai_api_key
                )

                self.qdrant_client = QdrantClient(
                    url=settings.qdrant_url,
                    api_key=settings.qdrant_api_key
                )

                #  QdrantVectorStoreë¡œ ë³€ê²½ (deprecation ê²½ê³  í•´ê²°)
                self.daily_conversation_store = QdrantVectorStore(
                    client=self.qdrant_client,
                    collection_name=settings.daily_conversation_collection,
                    embedding=self.embeddings  # embeddings -> embeddingìœ¼ë¡œ ë³€ê²½
                )
                self.letter_memory_store = QdrantVectorStore(
                    client=self.qdrant_client,
                    collection_name=settings.letter_memory_collection,
                    embedding=self.embeddings
                )
                self.object_memory_store = QdrantVectorStore(
                    client=self.qdrant_client,
                    collection_name=settings.object_memory_collection,
                    embedding=self.embeddings
                )

                # ì„±ëŠ¥ ìµœì í™” ì„¤ì •
                self.RELEVANCE_THRESHOLD = 0.3
                self.MAX_SEARCH_RESULTS = 3
                self.SEARCH_TIMEOUT = 10.0

                self._initialized = True
                logger.info(" AdvancedRAGService ì´ˆê¸°í™” ì™„ë£Œ")
                
            except Exception as e:
                logger.error(f" AdvancedRAGService ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                raise

    async def search_memories(self, query: str, authKeyId: str) -> List[Dict]:
        """ ìµœì í™”ëœ ë©”ëª¨ë¦¬ ê²€ìƒ‰"""
        try:
            logger.info(f"ğŸ” RAG ê²€ìƒ‰ ì‹œì‘: query='{query}', authKeyId='{authKeyId}'")
            
            # ì…ë ¥ ê²€ì¦
            if not query or not query.strip():
                logger.warning(" ë¹ˆ ê²€ìƒ‰ì–´ - ê²€ìƒ‰ ìƒëµ")
                return []
                
            if not authKeyId:
                logger.warning(" authKeyId ì—†ìŒ - ê²€ìƒ‰ ìƒëµ")
                return []

            query = query.strip()
            
            #  ë³‘ë ¬ ê²€ìƒ‰ with í•„í„°ë§
            auth_filter = Filter(
                must=[
                    FieldCondition(
                        key="metadata.authKeyId",
                        match=MatchValue(value=authKeyId)
                    )
                ]
            )

            search_tasks = []
            
            # ê° ì»¬ë ‰ì…˜ì—ì„œ í•„í„°ë§ëœ ê²€ìƒ‰ ìˆ˜í–‰
            for store_name, store in [
                ("letter", self.letter_memory_store),
                ("object", self.object_memory_store),
                ("daily", self.daily_conversation_store)
            ]:
                task = asyncio.create_task(
                    self._search_with_filter(store, query, auth_filter, store_name)
                )
                search_tasks.append(task)

            # íƒ€ì„ì•„ì›ƒê³¼ í•¨ê»˜ ë³‘ë ¬ ì‹¤í–‰
            try:
                search_results = await asyncio.wait_for(
                    asyncio.gather(*search_tasks, return_exceptions=True),
                    timeout=self.SEARCH_TIMEOUT
                )
            except asyncio.TimeoutError:
                logger.warning(f" ê²€ìƒ‰ íƒ€ì„ì•„ì›ƒ ({self.SEARCH_TIMEOUT}ì´ˆ) - ë¶€ë¶„ ê²°ê³¼ ë°˜í™˜")
                search_results = []

            # ê²°ê³¼ í†µí•© ë° ì •ë¦¬
            all_results = []
            for result in search_results:
                if isinstance(result, list):
                    all_results.extend(result)
                elif isinstance(result, Exception):
                    logger.warning(f"âš ï¸ ê²€ìƒ‰ ì˜¤ë¥˜ ë¬´ì‹œ: {result}")

            logger.info(f" ì „ì²´ ê²€ìƒ‰ ê²°ê³¼: {len(all_results)}ê°œ")

            # ì ìˆ˜ ê¸°ì¤€ í•„í„°ë§ ë° ì •ë ¬
            filtered_results = [
                r for r in all_results 
                if r.get("score", 0) >= self.RELEVANCE_THRESHOLD
            ]
            
            # ì ìˆ˜ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
            sorted_results = sorted(
                filtered_results, 
                key=lambda x: x.get("score", 0), 
                reverse=True
            )

            # ìµœëŒ€ ê°œìˆ˜ ì œí•œ
            final_results = sorted_results[:self.MAX_SEARCH_RESULTS]
            
            logger.info(f" ìµœì¢… ê²€ìƒ‰ ê²°ê³¼: {len(final_results)}ê°œ")
            for r in final_results:
                logger.info(f"   [{r['collection']}] score: {r['score']:.4f} - {r['content'][:30]}...")

            return final_results

        except Exception as e:
            logger.error(f" ê¸°ì–µ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    async def _search_with_filter(
        self, 
        store: QdrantVectorStore, 
        query: str, 
        auth_filter: Filter, 
        collection_name: str
    ) -> List[Dict]:
        """í•„í„°ë§ê³¼ í•¨ê»˜ ê°œë³„ ì»¬ë ‰ì…˜ ê²€ìƒ‰"""
        try:
            # QdrantVectorStoreì˜ ìƒˆë¡œìš´ API ì‚¬ìš©
            docs_and_scores = await store.asimilarity_search_with_score(
                query=query,
                k=self.MAX_SEARCH_RESULTS,
                filter=auth_filter  # í•„í„° ì ìš©
            )
            
            results = []
            for doc, score in docs_and_scores:
                meta = doc.metadata or {}
                results.append({
                    "content": doc.page_content,
                    "metadata": meta,
                    "collection": collection_name,
                    "score": score,
                    "date_text": format_date_relative(meta.get("date", ""))
                })
                
            logger.debug(f" {collection_name} ê²€ìƒ‰: {len(results)}ê°œ ê²°ê³¼")
            return results
            
        except Exception as e:
            logger.warning(f" {collection_name} ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    async def store_memory(self, content: str, authKeyId: str, memory_type: str, **kwargs) -> Dict:
        """ë©”ëª¨ë¦¬ ì €ì¥"""
        try:
            metadata = {
                "authKeyId": authKeyId,
                "memory_type": memory_type,
                "created_at": datetime.utcnow().isoformat()
            }
            
            # ì¶”ê°€ ë©”íƒ€ë°ì´í„° ë³‘í•©
            for key in ["item_id", "item_type", "source", "date", "title", "tags", "collection"]:
                if key in kwargs:
                    metadata[key] = kwargs[key]

            store = self._get_store_by_type(memory_type)
            doc = Document(page_content=content, metadata=metadata)
            
            await store.aadd_documents([doc])

            logger.info(f" ê¸°ì–µ ì €ì¥ ì™„ë£Œ: type={memory_type}")
            return {"status": "stored", "collection": store.collection_name}

        except Exception as e:
            logger.error(f" ê¸°ì–µ ì €ì¥ ì‹¤íŒ¨: {e}")
            return {"status": "failed", "error": str(e)}

    async def store_memory_with_metadata(
        self,
        id: str,
        content: str,
        page_content: str,
        memory_type: str,
        **metadata
    ) -> Dict:
        """ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ ë©”ëª¨ë¦¬ ì €ì¥"""
        try:
            metadata.update({
                "id": id,
                "memory_type": memory_type,
                "created_at": datetime.utcnow().isoformat()
            })

            store = self._get_store_by_type(memory_type)
            doc = Document(page_content=page_content, metadata=metadata)
            await store.aadd_documents([doc])

            logger.info(f" store_memory_with_metadata ì™„ë£Œ: type={memory_type}")
            return {"status": "stored", "collection": store.collection_name}

        except Exception as e:
            logger.error(f" store_memory_with_metadata ì‹¤íŒ¨: {e}")
            return {"status": "failed", "error": str(e)}

    async def delete_memories_with_filter(self, collection_name: str, filter_condition: Dict) -> int:
        """í•„í„° ì¡°ê±´ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì‚­ì œ"""
        try:
            store = self._get_store_by_collection(collection_name)
            await store.adelete(filter=filter_condition)
            logger.info(f" Qdrantì—ì„œ ì‚­ì œ ì™„ë£Œ: {collection_name} (ì¡°ê±´: {filter_condition})")
            return 1
        except Exception as e:
            logger.error(f" delete_memories_with_filter ì‹¤íŒ¨: {e}")
            return 0

    def _get_store_by_type(self, memory_type: str) -> QdrantVectorStore:
        """ë©”ëª¨ë¦¬ íƒ€ì…ë³„ ì €ì¥ì†Œ ë°˜í™˜"""
        if memory_type == "letter":
            return self.letter_memory_store
        elif memory_type in ["keepsake", "photo"]:
            return self.object_memory_store
        else:
            return self.daily_conversation_store

    def _get_store_by_collection(self, collection_name: str) -> QdrantVectorStore:
        """ì»¬ë ‰ì…˜ëª…ë³„ ì €ì¥ì†Œ ë°˜í™˜"""
        if collection_name == settings.letter_memory_collection:
            return self.letter_memory_store
        elif collection_name == settings.object_memory_collection:
            return self.object_memory_store
        elif collection_name == settings.daily_conversation_collection:
            return self.daily_conversation_store
        else:
            raise ValueError(f" ì§€ì›í•˜ì§€ ì•ŠëŠ” ì»¬ë ‰ì…˜ ì´ë¦„: {collection_name}")

#  Singleton ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
advanced_rag_service = AdvancedRAGService()