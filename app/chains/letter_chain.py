# app/chains/letter_chain.py

from datetime import datetime
import time

from langchain.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import ChatOpenAI

from app.schemas.letter_schemas import LetterProcessInternalResult
from app.services.advanced_rag_service import advanced_rag_service
from app.services.database_service import database_service
from app.utils.logger import logger
from app.prompts.letter_prompt import LetterPrompts
from app.config import settings


class LetterChain:
    def __init__(self):
        self.llm = ChatOpenAI(
            model="gpt-4o",
            temperature=0.5,
            openai_api_key=settings.openai_api_key
        )
        self.output_parser = StrOutputParser()

    async def process_letter(self,letter_id: str, user_id: str, authKeyId: str, letter_text: str) -> LetterProcessInternalResult:
        try:
            start_time = time.time()

            logger.debug(f"[ process_letter ì‹œì‘] user_id={user_id}, authKeyId={authKeyId}")
            logger.debug(f"[ ì…ë ¥ í¸ì§€ ë‚´ìš©] {letter_text[:100]}...")

            #  ê³ ì¸ ì •ë³´ ì¡°íšŒ (DB)
            deceased_info = await database_service.get_deceased_by_auth_key(authKeyId)
            logger.debug(f"[ğŸ§‘â€ğŸ’¼ ê³ ì¸ ì •ë³´ ì¡°íšŒ ì™„ë£Œ] {deceased_info}")

            #  í”„ë¡¬í”„íŠ¸ ì¤€ë¹„
            summary_prompt = PromptTemplate.from_template(LetterPrompts.LETTER_SUMMARY)
            response_prompt = PromptTemplate.from_template(LetterPrompts.LETTER_RESPONSE)

            summary_chain = summary_prompt | self.llm | self.output_parser
            response_chain = response_prompt | self.llm | self.output_parser

            #  AI ë‹µì¥ ìƒì„± (ì €ì¥ ì•ˆ í•¨)
            response_input = {
                "title": "",
                "content": letter_text,
                "deceased_name": deceased_info["name"],
                "relation_to_user": deceased_info["relation_to_user"],
                "personality": deceased_info["personality"],
                "speaking_style": deceased_info["speaking_style"],
                "memory_context": ""
            }
            logger.debug(f"[ response_chain ì…ë ¥ê°’] {response_input}")
            response = await response_chain.ainvoke(response_input)

            #  ìš”ì•½ ìƒì„± í›„ RAGì— ì €ì¥
            summary_input = {
                "user_letter": letter_text,
                "ai_response": response,
                "deceased_name": deceased_info["name"],
                "relation_to_user": deceased_info["relation_to_user"]
            }
            logger.debug(f"[ summary_chain ì…ë ¥ê°’] {summary_input}")
            summary = await summary_chain.ainvoke(summary_input)

            store_result = await advanced_rag_service.store_memory(
                content=summary,
                authKeyId=authKeyId,
                memory_type="letter",
                item_id=f"letter_{datetime.utcnow().timestamp()}",
                item_type="letter",
                source="letter",
                tags=["letter", "ìš”ì•½"],
                date=datetime.today().strftime("%Y-%m-%d")
            )
            logger.info(f"[ RAG ì €ì¥ ê²°ê³¼] {store_result}")

            elapsed = round(time.time() - start_time, 2)

            logger.debug(f"[ ì²˜ë¦¬ ì™„ë£Œ] elapsed={elapsed}s")

            return LetterProcessInternalResult(
                response=response,
                summary_stored=summary,
                emotion_tone=None,
                tags=["letter"],
                processing_time=elapsed
            )

        except Exception as e:
            logger.error(f" í¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return LetterProcessInternalResult(
                response="ì£„ì†¡í•´ìš”, ë‹µì¥ì„ ì¤€ë¹„í•˜ë‹¤ ë¬¸ì œê°€ ìƒê²¼ì–´ìš”."
            )


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
letter_chain = LetterChain()