from typing import Dict, List, Any
from datetime import datetime
import os
import asyncio

from langchain_openai import ChatOpenAI
from langchain.schema.runnable import Runnable, RunnablePassthrough, RunnableLambda
from langchain.prompts import ChatPromptTemplate
from langchain_core.chat_history import BaseChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.messages import HumanMessage, AIMessage

from app.config import settings
from app.utils.logger import logger
from app.services.advanced_rag_service import advanced_rag_service
from app.services.database_service import database_service
from app.prompts.chat_prompt import ChatPrompts

try:
    from langsmith import traceable
    os.environ["LANGCHAIN_TRACING_V2"] = "true"
    os.environ["LANGCHAIN_API_KEY"] = settings.langsmith_api_key or ""
    os.environ["LANGCHAIN_ENDPOINT"] = settings.langsmith_endpoint
    os.environ["LANGCHAIN_PROJECT"] = settings.langsmith_project
except ImportError:
    logger.warning(" LangSmith íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ - ì¶”ì  ê¸°ëŠ¥ ë¹„í™œì„±í™”")
    def traceable(name=None):
        def decorator(func):
            return func
        return decorator

class DatabaseChatMessageHistory(BaseChatMessageHistory):
    def __init__(self, session_id: str):
        self.session_id = session_id
        self._messages = []
        self._loaded = False

    async def _load_messages(self):
        if self._loaded:
            return
        try:
            conversations = await database_service.get_recent_conversations(self.session_id, limit=10)
            for conv in conversations:
                if conv["sender"] == "USER":
                    self._messages.append(HumanMessage(content=conv["message"]))
                else:
                    self._messages.append(AIMessage(content=conv["message"]))
            self._loaded = True
        except Exception as e:
            logger.error(f" íˆìŠ¤í† ë¦¬ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self._loaded = True

    @property
    def messages(self):
        return self._messages

    def add_message(self, message):
        self._messages.append(message)

    def clear(self):
        self._messages.clear()

class SplitResponseParser:
    MAX_RESPONSE_LENGTH = 300

    def __call__(self, text: Any) -> Dict[str, Any]:
        if isinstance(text, AIMessage):
            text = text.content
        elif not isinstance(text, str):
            text = str(text)

        logger.debug(f" GPT ì›ë³¸ ì‘ë‹µ: {text}")
        response, analysis, risk = "", "", "LOW"

        if "|" in text:
            try:
                parts = text.strip().split("|")
                response = parts[0].strip().lstrip("ì‘ë‹µ ë‚´ìš©:").strip().strip("'\"")
                analysis = parts[1].strip().lstrip("ë¶„ìœ„ê¸° ë¶„ì„ ìš”ì•½:").strip()
                risk = parts[2].strip().replace("ìœ„í—˜ë„:", "").strip().upper()
            except Exception as e:
                logger.warning(f" '|' íŒŒì‹± ì‹¤íŒ¨: {e}")
        else:
            lines = text.strip().splitlines()
            for line in lines:
                if "ì‘ë‹µ ë‚´ìš©:" in line:
                    response = line.split("ì‘ë‹µ ë‚´ìš©:", 1)[1].strip().strip("'\"")
                elif "ë¶„ìœ„ê¸° ë¶„ì„ ìš”ì•½:" in line:
                    analysis = line.split("ë¶„ìœ„ê¸° ë¶„ì„ ìš”ì•½:", 1)[1].strip()
                elif "ìœ„í—˜ë„:" in line:
                    risk = line.split("ìœ„í—˜ë„:", 1)[1].strip().upper()

        if not response:
            logger.warning(" ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨ - ê¸°ë³¸ ë©”ì‹œì§€ë¡œ ëŒ€ì²´")
            response = "ë¯¸ì•ˆí•´, ì§€ê¸ˆì€ ì˜ ëŒ€ë‹µì´ ì•ˆ ë¼. ë‹¤ì‹œ í•œ ë²ˆ ì´ì•¼ê¸°í•´ì¤„ë˜?"

        if len(response) > self.MAX_RESPONSE_LENGTH:
            response = response[:self.MAX_RESPONSE_LENGTH - 3] + "..."

        return {
            "output": {
                "response": response,
                "analysis": analysis,
                "risk": risk
            }
        }

class ChatChain:
    def __init__(self):
        self.llm = ChatOpenAI(
            model="gpt-4o",
            temperature=0.2,
            openai_api_key=settings.openai_api_key
        )
        self.base_chain = self._build_base_chain()
        self.chain_with_history = RunnableWithMessageHistory(
            runnable=self.base_chain,
            get_session_history=self._get_session_history,
            input_messages_key="input",
            history_messages_key="chat_history",
        )
        self.session_histories = {}
        
        # ğŸš€ ìµœì í™”: ì¤‘ë³µ ê²€ìƒ‰ ë°©ì§€ë¥¼ ìœ„í•œ ìºì‹œ
        self._recent_searches = {}  # session_id -> (query, timestamp, results)
        self.SEARCH_CACHE_DURATION = 30  # 30ì´ˆ

    def _build_base_chain(self) -> Runnable:
        prompt_template = ChatPromptTemplate.from_messages([
            ("system", ChatPrompts.RESPONSE_GENERATION)
        ])

        chain = (
            RunnablePassthrough.assign(
                memories=RunnableLambda(self._smart_search_memories),  #  ìŠ¤ë§ˆíŠ¸ ê²€ìƒ‰ìœ¼ë¡œ ë³€ê²½
                deceased_info=RunnableLambda(self._get_deceased_info)
            )
            | RunnablePassthrough.assign(
                memory_context=RunnableLambda(self._format_memories),
                deceased_name=lambda x: x["deceased_info"]["name"],
                deceased_nickname=lambda x: x["deceased_info"]["nickname"],
                personality=lambda x: x["deceased_info"]["personality"],
                speaking_style=lambda x: x["deceased_info"]["speaking_style"],
                hobbies=lambda x: x["deceased_info"]["hobbies"],
                age=lambda x: x["deceased_info"]["age"],
                user_name=lambda x: x["deceased_info"]["user_name"],
                relation_to_user=lambda x: x["deceased_info"]["relation_to_user"],
                conversation_history=lambda x: self._get_recent_text_messages(
                    self._get_session_history(x["authKeyId"])
                ),
                date_text=lambda x: self._extract_date_text(x.get("memories", [])),
                emotion_tone=lambda x: x.get("previous_analysis", "")
            )
            | prompt_template
            | self.llm
            | SplitResponseParser()
        )

        return chain

    def _get_session_history(self, session_id: str) -> BaseChatMessageHistory:
        if session_id not in self.session_histories:
            self.session_histories[session_id] = DatabaseChatMessageHistory(session_id)
        return self.session_histories[session_id]

    def _get_recent_text_messages(self, history: DatabaseChatMessageHistory, limit: int = 10) -> str:
        messages = history.messages[-limit:] if history else []
        text = []
        for m in messages:
            if isinstance(m, HumanMessage):
                text.append(f" {m.content}")
            elif isinstance(m, AIMessage):
                text.append(f" {m.content}")
        return "\n".join(text) if text else "(ìµœê·¼ ëŒ€í™” ì—†ìŒ)"

    def _extract_date_text(self, memories: List[Dict]) -> str:
        if not memories:
            return "ì˜ˆì „ ì–´ëŠ ë‚ "
        return memories[0].get("date_text", "í•œì°¸ ì „")

    def _get_last_analysis(self, session_id: str) -> str:
        history = self._get_session_history(session_id)
        if not history or not history.messages:
            return ""
        for msg in reversed(history.messages):
            if isinstance(msg, AIMessage):
                parsed = SplitResponseParser()(msg.content)
                return parsed["output"].get("analysis", "")
        return ""

    def _is_search_needed(self, user_input: str, session_id: str) -> bool:
        """ ìŠ¤ë§ˆíŠ¸ ê²€ìƒ‰ í•„ìš”ì„± íŒë‹¨"""
        query = user_input.strip().lower()
        
        # 1. ë„ˆë¬´ ì§§ì€ ê²€ìƒ‰ì–´
        if len(query) <= 2:
            logger.info(f"ğŸ’¬ ê²€ìƒ‰ ìƒëµ: ë„ˆë¬´ ì§§ì€ ê²€ìƒ‰ì–´ '{query}'")
            return False
            
        # 2. ì¼ë°˜ì ì¸ ì¸ì‚¬ë§/ê°ì‚¬ í‘œí˜„
        greeting_keywords = [
            "ì•ˆë…•", "ê³ ë§ˆì›Œ", "ê°ì‚¬", "ì‚¬ë‘í•´", "ë³´ê³ ì‹¶ì–´", "ì˜ì", "ì•ˆë…•íˆ",
            "ê´œì°®ì•„", "ì¢‹ì•„", "ì‹«ì–´", "í˜ë“¤ì–´", "ìŠ¬í¼", "ê¸°ë»"
        ]
        if any(keyword in query for keyword in greeting_keywords):
            logger.info(f" ê²€ìƒ‰ ìƒëµ: ì¼ë°˜ì ì¸ ê°ì • í‘œí˜„ '{query}'")
            return False
            
        # 3. ìºì‹œëœ ê²€ìƒ‰ ê²°ê³¼ í™•ì¸
        now = datetime.now().timestamp()
        if session_id in self._recent_searches:
            cached_query, cached_time, cached_results = self._recent_searches[session_id]
            if (now - cached_time) < self.SEARCH_CACHE_DURATION:
                # ìœ ì‚¬í•œ ê²€ìƒ‰ì–´ì¸ì§€ í™•ì¸
                similarity = self._calculate_similarity(query, cached_query)
                if similarity > 0.7:
                    logger.info(f" ê²€ìƒ‰ ìƒëµ: ìºì‹œëœ ê²°ê³¼ ì¬ì‚¬ìš© (ìœ ì‚¬ë„: {similarity:.2f})")
                    return False
                    
        return True

    def _calculate_similarity(self, query1: str, query2: str) -> float:
        """ê°„ë‹¨í•œ ë¬¸ìì—´ ìœ ì‚¬ë„ ê³„ì‚°"""
        words1 = set(query1.split())
        words2 = set(query2.split())
        intersection = words1 & words2
        union = words1 | words2
        return len(intersection) / len(union) if union else 0

    async def _smart_search_memories(self, data: Dict) -> List[Dict]:
        """ ìŠ¤ë§ˆíŠ¸ ë©”ëª¨ë¦¬ ê²€ìƒ‰ - ì¤‘ë³µ ì œê±° ë° ìºì‹±"""
        try:
            query = data["user_input"].strip()
            session_id = data["authKeyId"]
            
            # ê²€ìƒ‰ í•„ìš”ì„± íŒë‹¨
            if not self._is_search_needed(query, session_id):
                return []
                
            # ìºì‹œ í™•ì¸
            now = datetime.now().timestamp()
            if session_id in self._recent_searches:
                cached_query, cached_time, cached_results = self._recent_searches[session_id]
                if (now - cached_time) < self.SEARCH_CACHE_DURATION:
                    similarity = self._calculate_similarity(query.lower(), cached_query)
                    if similarity > 0.7:
                        logger.info(f" ìºì‹œëœ ê²€ìƒ‰ ê²°ê³¼ ì¬ì‚¬ìš©: '{query}' â‰ˆ '{cached_query}'")
                        return cached_results

            logger.info(f" ìƒˆë¡œìš´ ë©”ëª¨ë¦¬ ê²€ìƒ‰ ì‹¤í–‰: '{query}'")

            # ì‹¤ì œ ê²€ìƒ‰ ìˆ˜í–‰
            try:
                results = await asyncio.wait_for(
                    advanced_rag_service.search_memories(
                        query=query,
                        authKeyId=session_id
                    ),
                    timeout=10.0  # íƒ€ì„ì•„ì›ƒ ë‹¨ì¶•
                )
                
                # ê²°ê³¼ ìºì‹±
                self._recent_searches[session_id] = (query.lower(), now, results)
                
                # ìºì‹œ ì •ë¦¬ (ìµœëŒ€ 100ê°œ ì„¸ì…˜ë§Œ ìœ ì§€)
                if len(self._recent_searches) > 100:
                    oldest_session = min(self._recent_searches.keys(), 
                                       key=lambda k: self._recent_searches[k][1])
                    del self._recent_searches[oldest_session]
                
                logger.info(f" ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
                return results
                
            except asyncio.TimeoutError:
                logger.warning(f" ê²€ìƒ‰ íƒ€ì„ì•„ì›ƒ: '{query}' - ë¹ˆ ê²°ê³¼ ë°˜í™˜")
                return []

        except Exception as e:
            logger.error(f" ë©”ëª¨ë¦¬ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    @traceable(name="generate_response")
    async def generate_response(self, user_input: str, user_id: str, authKeyId: str) -> Dict:
        try:
            session_history = self._get_session_history(authKeyId)
            if isinstance(session_history, DatabaseChatMessageHistory):
                await session_history._load_messages()

            input_data = {
                "input": user_input,
                "user_input": user_input,
                "user_id": user_id,
                "authKeyId": authKeyId,
                "previous_analysis": self._get_last_analysis(authKeyId)
            }

            logger.info(f" ì±„íŒ… ì‘ë‹µ ìƒì„± ì‹œì‘: '{user_input[:30]}...'")

            ai_output = await self.chain_with_history.ainvoke(
                input_data,
                config={"configurable": {"session_id": authKeyId}}
            )

            result = ai_output["output"]

            await self._save_conversation(authKeyId, user_input, result["response"])

            # ì‚¬ìš©ëœ ë©”ëª¨ë¦¬ ì •ë³´ ì •ë¦¬
            raw_memories = input_data.get("memories", [])
            used_memories = [
                {
                    "collection": m["collection"],
                    "content": m["content"],
                    "score": round(m.get("score", 0.0), 4),
                    "date_text": m.get("date_text"),
                    "emotion_tone": m["metadata"].get("emotion_tone"),
                    "tags": m["metadata"].get("tags"),
                    "relevance_score": m.get("relevance_score")
                }
                for m in raw_memories
            ]

            logger.info(f" ì‘ë‹µ ìƒì„± ì™„ë£Œ: {len(result['response'])}ì, ë©”ëª¨ë¦¬ {len(used_memories)}ê°œ ì‚¬ìš©")

            return {
                "status": "success",
                "response": result["response"],
                "emotion_analysis": result["analysis"],
                "used_memories": used_memories,
                "search_cached": len(raw_memories) == 0,  # ê²€ìƒ‰ì´ ìºì‹±ë˜ì—ˆëŠ”ì§€ í‘œì‹œ
                "timestamp": datetime.now().isoformat()
            }

        except Exception as e:
            logger.error(f" ëŒ€í™” ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                "status": "error",
                "response": "ì£„ì†¡í•´ìš”, ì§€ê¸ˆì€ ìƒê°ì´ ì˜ ì •ë¦¬ë˜ì§€ ì•Šë„¤ìš”. ë‹¤ì‹œ í•œ ë²ˆ ë§í•´ì¤„ë˜ìš”?",
                "error": str(e)
            }

    async def _get_deceased_info(self, data: Dict) -> Dict:
        return await database_service.get_deceased_by_auth_key(data["authKeyId"])

    def _format_memories(self, data: Dict) -> str:
        memories = data.get("memories", [])
        if not memories:
            return ""
        memory_texts = []
        for m in memories[:2]:
            date_text = m.get("date_text", "ì–´ëŠ ë‚ ")
            content = m["content"]
            if len(content) > 50:
                content = content[:47] + "..."
            memory_texts.append(f"{date_text}ì— ìˆì—ˆë˜ ì¼: {content}")
        return " ê´€ë ¨ ê¸°ì–µ:\n" + "\n".join(memory_texts)

    async def _save_conversation(self, authKeyId: str, user_message: str, ai_response: str):
        try:
            await database_service.save_conversation(
                authKeyId=authKeyId,
                sender="USER",
                message=user_message
            )
            await database_service.save_conversation(
                authKeyId=authKeyId,
                sender="CHATBOT",
                message=ai_response
            )
        except Exception as e:
            logger.error(f" ëŒ€í™” ì €ì¥ ì‹¤íŒ¨: {e}")

chat_chain = ChatChain()