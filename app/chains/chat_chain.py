from typing import Dict, List, Any, Optional
from datetime import datetime
import os
import asyncio
import re

from langchain_openai import ChatOpenAI
from langchain.schema.runnable import Runnable, RunnablePassthrough, RunnableLambda
from langchain.prompts import ChatPromptTemplate
from langchain_core.chat_history import BaseChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.messages import HumanMessage, AIMessage

from app.config import settings
from app.utils.logger import logger
from app.services.advanced_rag_service import advanced_rag_service
from app.services.database_service import database_service
from app.prompts.chat_prompt import ChatPrompts

# LangSmith ì„¤ì •
try:
    from langsmith import traceable
    os.environ["LANGCHAIN_TRACING_V2"] = "true"
    os.environ["LANGCHAIN_API_KEY"] = settings.langsmith_api_key or ""
    os.environ["LANGCHAIN_ENDPOINT"] = settings.langsmith_endpoint
    os.environ["LANGCHAIN_PROJECT"] = settings.langsmith_project
except ImportError:
    logger.warning(" LangSmith íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ - ì¶”ì  ê¸°ëŠ¥ ë¹„í™œì„±í™”")
    def traceable(name=None):
        def decorator(func):
            return func
        return decorator


class DatabaseChatMessageHistory(BaseChatMessageHistory):
    """ë°ì´í„°ë² ì´ìŠ¤ ê¸°ë°˜ ì±„íŒ… íˆìŠ¤í† ë¦¬ ê´€ë¦¬"""
    
    def __init__(self, session_id: str):
        self.session_id = session_id
        self._messages = []
        self._loaded = False

    async def _load_messages(self):
        """ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ëŒ€í™” íˆìŠ¤í† ë¦¬ ë¡œë“œ"""
        if self._loaded:
            return
            
        try:
            conversations = await database_service.get_recent_conversations(
                self.session_id, 
                limit=10
            )
            
            for conv in conversations:
                if conv["sender"] == "USER":
                    self._messages.append(HumanMessage(content=conv["message"]))
                else:
                    self._messages.append(AIMessage(content=conv["message"]))
                    
            self._loaded = True
            logger.debug(f" íˆìŠ¤í† ë¦¬ ë¡œë“œ ì™„ë£Œ: {len(self._messages)}ê°œ ë©”ì‹œì§€")
            
        except Exception as e:
            logger.error(f" íˆìŠ¤í† ë¦¬ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self._loaded = True

    @property
    def messages(self):
        return self._messages

    def add_message(self, message):
        self._messages.append(message)

    def clear(self):
        self._messages.clear()


class ResponseParser:
    """GPT ì‘ë‹µ íŒŒì‹± ë° í¬ë§·íŒ…"""
    
    MAX_RESPONSE_LENGTH = 300
    METADATA_PREFIXES = ('ìš”ì•½:', 'ìœ„í—˜ë„:', 'ë¶„ì„:')
    
    def __call__(self, text: Any) -> Dict[str, Any]:
        if isinstance(text, AIMessage):
            text = text.content
        elif not isinstance(text, str):
            text = str(text)

        logger.debug(f" GPT ì›ë³¸ ì‘ë‹µ: {text[:100]}...")
        
        response = self._extract_response(text)
        analysis = self._extract_analysis(text)
        risk = self._extract_risk(text)

        # ì‘ë‹µ ê¸¸ì´ ì œí•œ
        if len(response) > self.MAX_RESPONSE_LENGTH:
            response = response[:self.MAX_RESPONSE_LENGTH - 3] + "..."

        logger.info(f" íŒŒì‹± ì™„ë£Œ - ì‘ë‹µ: {response[:50]}... | ë¶„ì„: {analysis[:30]}...")

        return {
            "output": {
                "response": response,
                "analysis": analysis,
                "risk": risk
            }
        }
    
    def _extract_response(self, text: str) -> str:
        """[ëŒ€ë‹µ]: í¬í•¨ ì‘ë‹µ íŒŒì‹± (GPT ì¶œë ¥ í˜•ì‹ ëŒ€ì‘)"""
        lines = text.strip().split('\n')

        # 0. [ëŒ€ë‹µ]: í‚¤ì›Œë“œ ê¸°ë°˜ ìš°ì„  íŒŒì‹±
        for line in lines:
            if line.strip().startswith("[ëŒ€ë‹µ]:"):
                return line.strip().replace("[ëŒ€ë‹µ]:", "").strip().strip('"')

        # 1. ì¼ë°˜ ë©”íƒ€ë°ì´í„° í•„í„° ê¸°ë°˜
        for line in lines:
            line = line.strip()
            if line and not line.startswith(self.METADATA_PREFIXES):
                if line.startswith('"') and line.endswith('"'):
                    return line[1:-1]
                return line

        # 2. | êµ¬ë¶„ì ê¸°ë°˜
        if "|" in text:
            try:
                response = text.strip().split("|")[0].strip()
                response = response.lstrip("ì‘ë‹µ ë‚´ìš©:").strip().strip("'\"")
                if response:
                    return response
            except Exception as e:
                logger.warning(f" '|' íŒŒì‹± ì‹¤íŒ¨: {e}")

        # 3. "ì‘ë‹µ ë‚´ìš©:" í‚¤ì›Œë“œ
        for line in lines:
            if "ì‘ë‹µ ë‚´ìš©:" in line:
                response = line.split("ì‘ë‹µ ë‚´ìš©:", 1)[1].strip().strip("'\"")
                if response:
                    return response

        # 4. ì²« ë¬¸ì¥ fallback
        first_sentence = text.split('.')[0].strip()
        if first_sentence and len(first_sentence) > 5:
            return first_sentence

        # 5. ì „ì²´ ì‚¬ìš© fallback
        if text.strip() and len(text.strip()) > 10:
            return text.strip()

        # 6. ë§ˆì§€ë§‰ fallback
        logger.warning(" GPT ì‘ë‹µì´ ë¹„ì–´ìˆê±°ë‚˜ ë„ˆë¬´ ì§§ìŒ - ê¸°ë³¸ ë©”ì‹œì§€ ì‚¬ìš©")
        return "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"
    
    def _extract_analysis(self, text: str) -> str:
        """ë¶„ìœ„ê¸° ë¶„ì„ ì¶”ì¶œ"""
        try:
            if "ìš”ì•½:" in text:
                return text.split("ìš”ì•½:")[1].split("\n")[0].strip()
            elif "ë¶„ìœ„ê¸° ë¶„ì„ ìš”ì•½:" in text:
                return text.split("ë¶„ìœ„ê¸° ë¶„ì„ ìš”ì•½:")[1].split("\n")[0].strip()
            elif "|" in text and len(text.split("|")) > 1:
                return text.split("|")[1].strip()
        except Exception:
            pass
        return ""
    
    def _extract_risk(self, text: str) -> str:
        """ìœ„í—˜ë„ ì¶”ì¶œ"""
        try:
            if "ìœ„í—˜ë„:" in text:
                return text.split("ìœ„í—˜ë„:")[1].strip().upper()
            elif "|" in text and len(text.split("|")) > 2:
                return text.split("|")[2].strip().replace("ìœ„í—˜ë„:", "").strip().upper()
        except Exception:
            pass
        return "LOW"


class MemorySearchStrategy:
    """ë©”ëª¨ë¦¬ ê²€ìƒ‰ ì „ëµ ê´€ë¦¬"""
    
    SKIP_KEYWORDS = {"ì‘", "ê·¸ë˜", "ì•Œê² ì–´", "ê³ ë§ˆì›Œ", "ã…ã…", "ã…‹ã…‹", "ì˜ì", "í•˜í•˜", "í—", "ìŒ", "ìœ¼ì‘", "ì‘ì‘", "ì–´"}
    SIMILARITY_THRESHOLD = 0.6
    
    @classmethod
    def should_skip_search(cls, user_input: str, history: DatabaseChatMessageHistory) -> bool:
        """ë©”ëª¨ë¦¬ ê²€ìƒ‰ì„ ìƒëµí• ì§€ ê²°ì •"""
        cleaned = user_input.strip().lower()
        
        # 1. ë„ˆë¬´ ì§§ê±°ë‚˜ ë¬´ì˜ë¯¸í•œ ë°œí™”
        if len(cleaned) <= 2 or cleaned in cls.SKIP_KEYWORDS:
            logger.info(" ë‹¨ìˆœ ì‘ë‹µ ê°ì§€ â†’ ê¸°ì–µ ê²€ìƒ‰ ìƒëµ")
            return True
        
        # 2. ìµœê·¼ AI ì‘ë‹µê³¼ ì¤‘ë³µë„ê°€ ë†’ì€ ê²½ìš°
        recent_ai_msgs = [
            m.content.lower() for m in reversed(history.messages[-50:]) 
            if isinstance(m, AIMessage)
        ]
        
        user_keywords = set(cleaned.split())
        for msg in recent_ai_msgs:
            msg_words = set(msg.split())
            overlap = user_keywords & msg_words
            if len(overlap) / max(len(user_keywords), 1) >= cls.SIMILARITY_THRESHOLD:
                logger.info(" ìµœê·¼ ì‘ë‹µê³¼ ìœ ì‚¬í•œ ë‚´ìš© ë°œê²¬ â†’ ê¸°ì–µ ê²€ìƒ‰ ìƒëµ")
                return True
        
        return False


class ChatChain:
    """AI ì¶”ëª¨ ëŒ€í™” ì²´ì¸ ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.llm = ChatOpenAI(
            model="gpt-4o",
            temperature=0.2,
            openai_api_key=settings.openai_api_key
        )
        
        self.response_parser = ResponseParser()
        self.base_chain = self._build_chain()
        self.chain_with_history = RunnableWithMessageHistory(
            runnable=self.base_chain,
            get_session_history=self._get_session_history,
            input_messages_key="input",
            history_messages_key="chat_history",
        )
        self.session_histories = {}
        
        logger.info(" ChatChain ì´ˆê¸°í™” ì™„ë£Œ")

    def _build_chain(self) -> Runnable:
        """LangChain ì²´ì¸ êµ¬ì„±"""
        prompt_template = ChatPromptTemplate.from_messages([
            ("system", ChatPrompts.RESPONSE_GENERATION)
        ])

        return (
            RunnablePassthrough.assign(
                memories=RunnableLambda(self._search_memories),
                deceased_info=RunnableLambda(self._get_deceased_info)
            )
            | RunnablePassthrough.assign(
                memory_context=RunnableLambda(self._format_memories),
                **self._create_context_variables()
            )
            | prompt_template
            | self.llm
            | self.response_parser
        )
    
    def _create_context_variables(self) -> Dict:
        """ì»¨í…ìŠ¤íŠ¸ ë³€ìˆ˜ ìƒì„±"""
        return {
            "deceased_name": lambda x: x["deceased_info"].get("name", ""),
            "deceased_nickname": lambda x: x["deceased_info"].get("nickname", ""),
            "personality": lambda x: x["deceased_info"].get("personality", ""),
            "speaking_style": lambda x: x["deceased_info"].get("speaking_style", ""),
            "hobbies": lambda x: x["deceased_info"].get("hobbies", ""),
            "age": lambda x: x["deceased_info"].get("age", ""),
            "user_name": lambda x: x["deceased_info"].get("user_name", ""),
            "relation_to_user": lambda x: x["deceased_info"].get("relation_to_user", ""),
            "conversation_history": lambda x: self._get_recent_messages(
                self._get_session_history(x["authKeyId"])
            ),
            "date_text": lambda x: self._extract_date_text(x.get("memories", [])),
            "emotion_tone": lambda x: x.get("previous_analysis", "")
        }

    def _get_session_history(self, session_id: str) -> DatabaseChatMessageHistory:
        """ì„¸ì…˜ íˆìŠ¤í† ë¦¬ ê´€ë¦¬"""
        if session_id not in self.session_histories:
            self.session_histories[session_id] = DatabaseChatMessageHistory(session_id)
        return self.session_histories[session_id]

    def _get_recent_messages(self, history: DatabaseChatMessageHistory, limit: int = 10) -> str:
        """ìµœê·¼ ëŒ€í™” ë©”ì‹œì§€ í¬ë§·íŒ…"""
        try:
            messages = history.messages[-limit:] if history else []
            formatted = []
            
            for m in messages:
                if isinstance(m, HumanMessage):
                    formatted.append(f"ì‚¬ìš©ì: {m.content}")
                elif isinstance(m, AIMessage):
                    formatted.append(f"AI: {m.content}")
                    
            return "\n".join(formatted) if formatted else "(ìµœê·¼ ëŒ€í™” ì—†ìŒ)"
        except Exception as e:
            logger.warning(f" ë©”ì‹œì§€ í¬ë§·íŒ… ì‹¤íŒ¨: {e}")
            return "(ìµœê·¼ ëŒ€í™” ì—†ìŒ)"

    def _extract_date_text(self, memories: List[Dict]) -> str:
        """ë©”ëª¨ë¦¬ì—ì„œ ë‚ ì§œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        if not memories:
            return "ì˜ˆì „ ì–´ëŠ ë‚ "
        return memories[0].get("date_text", "í•œì°¸ ì „")

    def _get_last_analysis(self, session_id: str) -> str:
        """ë§ˆì§€ë§‰ ê°ì • ë¶„ì„ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°"""
        try:
            history = self._get_session_history(session_id)
            if not history or not history.messages:
                return ""
                
            for msg in reversed(history.messages):
                if isinstance(msg, AIMessage):
                    parsed = self.response_parser(msg.content)
                    return parsed["output"].get("analysis", "")
            return ""
        except Exception as e:
            logger.warning(f" ë§ˆì§€ë§‰ ë¶„ì„ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return ""

    @traceable(name="generate_response")
    async def generate_response(self, user_input: str, user_id: str, authKeyId: str) -> Dict:
        """ë©”ì¸ ì‘ë‹µ ìƒì„± í•¨ìˆ˜"""
        try:
            # ì„¸ì…˜ íˆìŠ¤í† ë¦¬ ë¡œë“œ
            session_history = self._get_session_history(authKeyId)
            if isinstance(session_history, DatabaseChatMessageHistory):
                await session_history._load_messages()

            # ë©”ëª¨ë¦¬ ê²€ìƒ‰ ì—¬ë¶€ ê²°ì •
            skip_rag = MemorySearchStrategy.should_skip_search(user_input, session_history)

            # ì…ë ¥ ë°ì´í„° êµ¬ì„±
            input_data = {
                "input": user_input,
                "user_input": user_input,
                "user_id": user_id,
                "authKeyId": authKeyId,
                "previous_analysis": self._get_last_analysis(authKeyId),
                "memories": []
            }

            # ë©”ëª¨ë¦¬ ê²€ìƒ‰ (ì„ íƒì )
            if not skip_rag:
                try:
                    memories = await self._search_memories(input_data)
                    input_data["memories"] = memories
                except Exception as e:
                    logger.warning(f" ë©”ëª¨ë¦¬ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                    input_data["memories"] = []

            logger.info(f" ì…ë ¥: {user_input[:30]}... | RAG ìƒëµ: {skip_rag} | ê¸°ì–µ ìˆ˜: {len(input_data['memories'])}")

            # AI ì‘ë‹µ ìƒì„±
            ai_output = await self.chain_with_history.ainvoke(
                input_data,
                config={"configurable": {"session_id": authKeyId}}
            )

            result = ai_output["output"]

            # ëŒ€í™” ì €ì¥ (ë¹„ë™ê¸°)
            asyncio.create_task(
                self._save_conversation(authKeyId, user_input, result["response"])
            )

            # ì‘ë‹µ êµ¬ì„±
            return {
                "status": "success",
                "response": result["response"],
                "emotion_analysis": result["analysis"],
                "used_memories": self._format_used_memories(input_data.get("memories", [])),
                "timestamp": datetime.now().isoformat()
            }

        except Exception as e:
            logger.error(f" ëŒ€í™” ìƒì„± ì‹¤íŒ¨: {e}")
            
            # ë©”ëª¨ë¦¬ ì—†ì´ë¼ë„ í”„ë¡¬í”„íŠ¸ë¡œ ì‘ë‹µ ìƒì„± ì‹œë„
            try:
                logger.info("ğŸ”„ ë©”ëª¨ë¦¬ ì—†ì´ ì¬ì‹œë„")
                fallback_input = {
                    "input": user_input,
                    "user_input": user_input,
                    "user_id": user_id,
                    "authKeyId": authKeyId,
                    "previous_analysis": "",
                    "memories": []
                }
                
                fallback_output = await self.chain_with_history.ainvoke(
                    fallback_input,
                    config={"configurable": {"session_id": authKeyId}}
                )
                
                result = fallback_output["output"]
                logger.info(" ë©”ëª¨ë¦¬ ì—†ì´ ì‘ë‹µ ìƒì„± ì„±ê³µ")
                
                return {
                    "status": "success",
                    "response": result["response"],
                    "emotion_analysis": result.get("analysis", ""),
                    "used_memories": [],
                    "timestamp": datetime.now().isoformat(),
                    "fallback": True
                }
                
            except Exception as fallback_error:
                logger.error(f" í´ë°± ì‘ë‹µë„ ì‹¤íŒ¨: {fallback_error}")
                return {
                    "status": "success",  # ì‚¬ìš©ì ê²½í—˜ì„ ìœ„í•´ success ìœ ì§€
                    "response": "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?",
                    "emotion_analysis": "",
                    "used_memories": [],
                    "timestamp": datetime.now().isoformat(),
                    "error": str(e)
                }

    async def _search_memories(self, data: Dict) -> List[Dict]:
        """ë©”ëª¨ë¦¬ ê²€ìƒ‰ ì‹¤í–‰"""
        try:
            query = data["user_input"].strip()
            
            # ê²€ìƒ‰ì–´ ê¸¸ì´ì— ë”°ë¥¸ íƒ€ì„ì•„ì›ƒ ì¡°ì •
            if len(query) <= 2:
                if len(query) == 1:
                    logger.info(" í•œ ê¸€ì ê²€ìƒ‰ì–´ëŠ” ê²€ìƒ‰ ìƒëµ")
                    return []
                    
                logger.info(f" ì§§ì€ ê²€ìƒ‰ì–´ '{query}' - ë¹ ë¥¸ ê²€ìƒ‰ ëª¨ë“œ")
                timeout = 5.0
                max_results = 3
            else:
                logger.info(f" ì¼ë°˜ ê²€ìƒ‰: '{query}'")
                timeout = 15.0
                max_results = 5

            result = await asyncio.wait_for(
                advanced_rag_service.search_memories(
                    query=query,
                    authKeyId=data["authKeyId"]
                ),
                timeout=timeout
            )
            
            return result[:max_results]

        except asyncio.TimeoutError:
            logger.warning(f" ê²€ìƒ‰ íƒ€ì„ì•„ì›ƒ: '{query}' - ë¹ˆ ê²°ê³¼ ë°˜í™˜")
            return []
        except Exception as e:
            logger.error(f" ë©”ëª¨ë¦¬ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    async def _get_deceased_info(self, data: Dict) -> Dict:
        """ê³ ì¸ ì •ë³´ ì¡°íšŒ"""
        try:
            return await database_service.get_deceased_by_auth_key(data["authKeyId"])
        except Exception as e:
            logger.warning(f" ê³ ì¸ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ê°’ ë°˜í™˜
            return {
                "name": "ì†Œì¤‘í•œ ë¶„",
                "nickname": "ì†Œì¤‘í•œ ë¶„",
                "personality": "ì¹œê·¼í•˜ê³  ë”°ëœ»í•œ",
                "speaking_style": "ë‹¤ì •í•˜ê³  ë¶€ë“œëŸ¬ìš´",
                "hobbies": "",
                "age": "",
                "user_name": "",
                "relation_to_user": "ì†Œì¤‘í•œ ì‚¬ëŒ"
            }

    def _format_memories(self, data: Dict) -> str:
        """ë©”ëª¨ë¦¬ ì»¨í…ìŠ¤íŠ¸ í¬ë§·íŒ…"""
        try:
            memories = data.get("memories", [])
            if not memories:
                return ""
                
            memory_texts = []
            for m in memories[:2]:  # ìµœëŒ€ 2ê°œë§Œ ì‚¬ìš©
                date_text = m.get("date_text", "ì–´ëŠ ë‚ ")
                content = m.get("content", "")
                
                # ë‚´ìš© ê¸¸ì´ ì œí•œ
                if len(content) > 50:
                    content = content[:47] + "..."
                    
                memory_texts.append(f"{date_text}ì— ìˆì—ˆë˜ ì¼: {content}")
                
            return " ê´€ë ¨ ê¸°ì–µ:\n" + "\n".join(memory_texts)
        except Exception as e:
            logger.warning(f" ë©”ëª¨ë¦¬ í¬ë§·íŒ… ì‹¤íŒ¨: {e}")
            return ""

    def _format_used_memories(self, memories: List[Dict]) -> List[Dict]:
        """ì‘ë‹µìš© ë©”ëª¨ë¦¬ ì •ë³´ í¬ë§·íŒ…"""
        try:
            return [
                {
                    "collection": m.get("collection", ""),
                    "content": m.get("content", ""),
                    "score": round(m.get("score", 0.0), 4),
                    "date_text": m.get("date_text", ""),
                    "emotion_tone": m.get("metadata", {}).get("emotion_tone", ""),
                    "tags": m.get("metadata", {}).get("tags", []),
                    "relevance_score": m.get("relevance_score", 0.0)
                }
                for m in memories
            ]
        except Exception as e:
            logger.warning(f" ë©”ëª¨ë¦¬ í¬ë§·íŒ… ì‹¤íŒ¨: {e}")
            return []

    async def _save_conversation(self, authKeyId: str, user_message: str, ai_response: str):
        """ëŒ€í™” ì €ì¥ (ë¹„ë™ê¸°)"""
        try:
            await database_service.save_conversation(
                authKeyId=authKeyId,
                sender="USER",
                message=user_message
            )
            await database_service.save_conversation(
                authKeyId=authKeyId,
                sender="CHATBOT",
                message=ai_response
            )
            logger.debug(" ëŒ€í™” ì €ì¥ ì™„ë£Œ")
        except Exception as e:
            logger.error(f" ëŒ€í™” ì €ì¥ ì‹¤íŒ¨: {e}")


# ê¸€ë¡œë²Œ ì¸ìŠ¤í„´ìŠ¤
chat_chain = ChatChain()